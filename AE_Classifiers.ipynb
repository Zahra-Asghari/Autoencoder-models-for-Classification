{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zahra-Asghari/Autoencoder-models-for-Classification/blob/main/AE_Classifiers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, LSTM, RepeatVector\n",
        "from keras.models import Model"
      ],
      "metadata": {
        "id": "o1zDjZmZzXNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Generate some random data\n",
        "np.random.seed(42)\n",
        "num_samples = 1000\n",
        "timesteps = 10\n",
        "input_dim = 5\n",
        "data = np.random.rand(num_samples, timesteps, input_dim)\n",
        "\n",
        "# Split the data into train and test sets\n",
        "train_size = int(num_samples * 0.8)\n",
        "x_train = data[:train_size]\n",
        "x_test = data[train_size:]\n",
        "\n",
        "# Define the autoencoder model\n",
        "input_shape = (timesteps, input_dim)\n",
        "encoder_inputs = Input(shape=input_shape)\n",
        "encoder_lstm = LSTM(64, return_sequences=True)(encoder_inputs)\n",
        "encoder_lstm = LSTM(32, return_sequences=False)(encoder_lstm)\n",
        "encoder_outputs = RepeatVector(timesteps)(encoder_lstm)\n",
        "decoder_lstm = LSTM(32, return_sequences=True)(encoder_outputs)\n",
        "decoder_lstm = LSTM(64, return_sequences=True)(decoder_lstm)\n",
        "decoder_outputs = LSTM(input_dim, return_sequences=True)(decoder_lstm)\n",
        "autoencoder = Model(inputs=encoder_inputs, outputs=decoder_outputs)\n",
        "autoencoder.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train the autoencoder\n",
        "batch_size = 32\n",
        "epochs = 50\n",
        "autoencoder.fit(x_train, x_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, x_test))\n",
        "\n",
        "# Test the autoencoder on some data\n",
        "x_test_reconstructed = autoencoder.predict(x_test)\n",
        "\n",
        "# Compute the mean squared error between the original and reconstructed data\n",
        "mse = np.mean(np.power(x_test - x_test_reconstructed, 2))\n",
        "print(f\"Mean squared error: {mse}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBvUiA2tzXcr",
        "outputId": "c6a6d1f3-eec4-4da6-fa98-e8ae6d9af231"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "25/25 [==============================] - 14s 125ms/step - loss: 0.2164 - val_loss: 0.1219\n",
            "Epoch 2/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 0.1040 - val_loss: 0.0937\n",
            "Epoch 3/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 0.0897 - val_loss: 0.0877\n",
            "Epoch 4/50\n",
            "25/25 [==============================] - 1s 32ms/step - loss: 0.0862 - val_loss: 0.0856\n",
            "Epoch 5/50\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 0.0847 - val_loss: 0.0849\n",
            "Epoch 6/50\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 0.0841 - val_loss: 0.0843\n",
            "Epoch 7/50\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 0.0836 - val_loss: 0.0841\n",
            "Epoch 8/50\n",
            "25/25 [==============================] - 2s 76ms/step - loss: 0.0834 - val_loss: 0.0838\n",
            "Epoch 9/50\n",
            "25/25 [==============================] - 2s 74ms/step - loss: 0.0832 - val_loss: 0.0838\n",
            "Epoch 10/50\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 0.0832 - val_loss: 0.0841\n",
            "Epoch 11/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.0832 - val_loss: 0.0837\n",
            "Epoch 12/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 0.0832 - val_loss: 0.0841\n",
            "Epoch 13/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.0833 - val_loss: 0.0837\n",
            "Epoch 14/50\n",
            "25/25 [==============================] - 1s 32ms/step - loss: 0.0831 - val_loss: 0.0837\n",
            "Epoch 15/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 0.0831 - val_loss: 0.0840\n",
            "Epoch 16/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.0831 - val_loss: 0.0838\n",
            "Epoch 17/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.0831 - val_loss: 0.0837\n",
            "Epoch 18/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 0.0831 - val_loss: 0.0838\n",
            "Epoch 19/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.0831 - val_loss: 0.0839\n",
            "Epoch 20/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.0831 - val_loss: 0.0838\n",
            "Epoch 21/50\n",
            "25/25 [==============================] - 1s 33ms/step - loss: 0.0831 - val_loss: 0.0837\n",
            "Epoch 22/50\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 0.0831 - val_loss: 0.0837\n",
            "Epoch 23/50\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 0.0831 - val_loss: 0.0837\n",
            "Epoch 24/50\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 0.0831 - val_loss: 0.0837\n",
            "Epoch 25/50\n",
            "25/25 [==============================] - 1s 30ms/step - loss: 0.0832 - val_loss: 0.0840\n",
            "Epoch 26/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.0831 - val_loss: 0.0839\n",
            "Epoch 27/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.0831 - val_loss: 0.0840\n",
            "Epoch 28/50\n",
            "25/25 [==============================] - 1s 30ms/step - loss: 0.0831 - val_loss: 0.0838\n",
            "Epoch 29/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 0.0831 - val_loss: 0.0837\n",
            "Epoch 30/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 0.0831 - val_loss: 0.0839\n",
            "Epoch 31/50\n",
            "25/25 [==============================] - 1s 30ms/step - loss: 0.0831 - val_loss: 0.0838\n",
            "Epoch 32/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 0.0831 - val_loss: 0.0838\n",
            "Epoch 33/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.0831 - val_loss: 0.0837\n",
            "Epoch 34/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 0.0831 - val_loss: 0.0836\n",
            "Epoch 35/50\n",
            "25/25 [==============================] - 1s 30ms/step - loss: 0.0831 - val_loss: 0.0838\n",
            "Epoch 36/50\n",
            "25/25 [==============================] - 1s 30ms/step - loss: 0.0830 - val_loss: 0.0838\n",
            "Epoch 37/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.0831 - val_loss: 0.0836\n",
            "Epoch 38/50\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 0.0830 - val_loss: 0.0837\n",
            "Epoch 39/50\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 0.0830 - val_loss: 0.0836\n",
            "Epoch 40/50\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 0.0829 - val_loss: 0.0833\n",
            "Epoch 41/50\n",
            "25/25 [==============================] - 1s 31ms/step - loss: 0.0827 - val_loss: 0.0831\n",
            "Epoch 42/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 0.0828 - val_loss: 0.0830\n",
            "Epoch 43/50\n",
            "25/25 [==============================] - 1s 32ms/step - loss: 0.0824 - val_loss: 0.0828\n",
            "Epoch 44/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 0.0821 - val_loss: 0.0825\n",
            "Epoch 45/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 0.0818 - val_loss: 0.0824\n",
            "Epoch 46/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 0.0817 - val_loss: 0.0822\n",
            "Epoch 47/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 0.0814 - val_loss: 0.0818\n",
            "Epoch 48/50\n",
            "25/25 [==============================] - 1s 30ms/step - loss: 0.0810 - val_loss: 0.0814\n",
            "Epoch 49/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 0.0809 - val_loss: 0.0814\n",
            "Epoch 50/50\n",
            "25/25 [==============================] - 1s 30ms/step - loss: 0.0808 - val_loss: 0.0815\n",
            "7/7 [==============================] - 3s 17ms/step\n",
            "Mean squared error: 0.0814885642018259\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.layers import Input, LSTM, RepeatVector, Dense\n",
        "from keras.models import Model\n",
        "\n",
        "# Generate some random labeled data\n",
        "np.random.seed(42)\n",
        "num_samples = 1000\n",
        "timesteps = 10\n",
        "input_dim = 5\n",
        "num_classes = 2\n",
        "data = np.random.rand(num_samples, timesteps, input_dim)\n",
        "labels = np.random.randint(num_classes, size=num_samples)\n",
        "\n",
        "# Define the input sequence shape\n",
        "input_shape = (timesteps, input_dim)\n",
        "\n",
        "# Define the encoder LSTM layer\n",
        "encoder_inputs = Input(shape=input_shape)\n",
        "encoder_lstm = LSTM(64, return_sequences=True)(encoder_inputs)\n",
        "encoder_lstm = LSTM(32, return_sequences=False)(encoder_lstm)\n",
        "encoder_outputs = RepeatVector(timesteps)(encoder_lstm)\n",
        "\n",
        "# Define the decoder LSTM layer\n",
        "decoder_lstm = LSTM(32, return_sequences=True)(encoder_outputs)\n",
        "decoder_lstm = LSTM(64, return_sequences=True)(decoder_lstm)\n",
        "decoder_outputs = LSTM(input_dim, return_sequences=True)(decoder_lstm)\n",
        "\n",
        "# Define the autoencoder model\n",
        "autoencoder = Model(inputs=encoder_inputs, outputs=decoder_outputs)\n",
        "\n",
        "# Compile the model\n",
        "autoencoder.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train the model end-to-end\n",
        "batch_size = 32\n",
        "epochs = 50\n",
        "autoencoder.fit(data, data, batch_size=batch_size, epochs=epochs)\n",
        "\n",
        "# Extract the encoded features\n",
        "encoder = Model(inputs=encoder_inputs, outputs=encoder_lstm)\n",
        "encoded_data = encoder.predict(data)\n",
        "\n",
        "# Define a feedforward neural network for classification\n",
        "input_shape = (encoded_data.shape[1],)\n",
        "inputs = Input(shape=input_shape)\n",
        "dense_1 = Dense(64, activation='relu')(inputs)\n",
        "dense_2 = Dense(32, activation='relu')(dense_1)\n",
        "outputs = Dense(num_classes, activation='softmax')(dense_2)\n",
        "classifier = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Compile the classifier\n",
        "classifier.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the classifier on the encoded features\n",
        "classifier.fit(encoded_data, labels, batch_size=batch_size, epochs=epochs)\n",
        "\n",
        "# Test the classifier on some data\n",
        "x_test = np.random.rand(1, timesteps, input_dim)\n",
        "encoded_x_test = encoder.predict(x_test)\n",
        "y_test = np.random.randint(num_classes, size=1)\n",
        "loss, accuracy = classifier.evaluate(encoded_x_test, y_test)\n",
        "print(f\"Loss: {loss}, Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gJt269C25vo",
        "outputId": "3c19442e-da19-406f-c6b1-06f070f4c9d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "32/32 [==============================] - 13s 34ms/step - loss: 0.1989\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 1s 34ms/step - loss: 0.0959\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 1s 34ms/step - loss: 0.0871\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 1s 34ms/step - loss: 0.0850\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 1s 34ms/step - loss: 0.0842\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 1s 34ms/step - loss: 0.0838\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 1s 42ms/step - loss: 0.0835\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 2s 50ms/step - loss: 0.0835\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 1s 40ms/step - loss: 0.0834\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 1s 32ms/step - loss: 0.0833\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 1s 33ms/step - loss: 0.0833\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 1s 33ms/step - loss: 0.0833\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 1s 33ms/step - loss: 0.0832\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 1s 33ms/step - loss: 0.0833\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 1s 34ms/step - loss: 0.0833\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 1s 34ms/step - loss: 0.0833\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 1s 34ms/step - loss: 0.0833\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 1s 38ms/step - loss: 0.0833\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 2s 47ms/step - loss: 0.0833\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 1s 43ms/step - loss: 0.0833\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 1s 34ms/step - loss: 0.0832\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 1s 34ms/step - loss: 0.0833\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 1s 34ms/step - loss: 0.0833\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 1s 33ms/step - loss: 0.0832\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 1s 35ms/step - loss: 0.0832\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 1s 34ms/step - loss: 0.0833\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 1s 34ms/step - loss: 0.0833\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 1s 34ms/step - loss: 0.0832\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 1s 40ms/step - loss: 0.0832\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 2s 51ms/step - loss: 0.0832\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 1s 40ms/step - loss: 0.0834\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 1s 34ms/step - loss: 0.0833\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 1s 35ms/step - loss: 0.0832\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 1s 35ms/step - loss: 0.0832\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 1s 34ms/step - loss: 0.0833\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 1s 34ms/step - loss: 0.0833\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 1s 34ms/step - loss: 0.0832\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 1s 33ms/step - loss: 0.0833\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 1s 34ms/step - loss: 0.0832\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 1s 43ms/step - loss: 0.0833\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 2s 48ms/step - loss: 0.0833\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 1s 38ms/step - loss: 0.0832\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 1s 34ms/step - loss: 0.0833\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 1s 34ms/step - loss: 0.0833\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 1s 34ms/step - loss: 0.0833\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 1s 34ms/step - loss: 0.0833\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 1s 34ms/step - loss: 0.0833\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 1s 34ms/step - loss: 0.0833\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 1s 34ms/step - loss: 0.0833\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 1s 33ms/step - loss: 0.0832\n",
            "32/32 [==============================] - 1s 5ms/step\n",
            "Epoch 1/50\n",
            "32/32 [==============================] - 1s 4ms/step - loss: 0.7266 - accuracy: 0.4810\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6942 - accuracy: 0.5070\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6986 - accuracy: 0.4950\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6973 - accuracy: 0.5250\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6958 - accuracy: 0.5190\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6976 - accuracy: 0.5210\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6961 - accuracy: 0.4970\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.6984 - accuracy: 0.4830\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6983 - accuracy: 0.5210\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.7030 - accuracy: 0.4930\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6987 - accuracy: 0.4900\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6977 - accuracy: 0.4870\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.5130\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6993 - accuracy: 0.4710\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6952 - accuracy: 0.4810\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6976 - accuracy: 0.4850\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6949 - accuracy: 0.4940\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6964 - accuracy: 0.4930\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6946 - accuracy: 0.4860\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6945 - accuracy: 0.4870\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6945 - accuracy: 0.5030\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6964 - accuracy: 0.4970\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6955 - accuracy: 0.4930\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6958 - accuracy: 0.4910\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6956 - accuracy: 0.5210\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6959 - accuracy: 0.5010\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6983 - accuracy: 0.5050\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6971 - accuracy: 0.4990\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6953 - accuracy: 0.5110\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6946 - accuracy: 0.5170\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.5210\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6979 - accuracy: 0.4890\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6967 - accuracy: 0.4980\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6948 - accuracy: 0.4930\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6967 - accuracy: 0.4990\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6953 - accuracy: 0.4870\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.4950\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.5190\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.7003 - accuracy: 0.4990\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6965 - accuracy: 0.4910\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6952 - accuracy: 0.5090\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6946 - accuracy: 0.4810\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6938 - accuracy: 0.4890\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6936 - accuracy: 0.4970\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6957 - accuracy: 0.4810\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6939 - accuracy: 0.5050\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6943 - accuracy: 0.4830\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6940 - accuracy: 0.4990\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.4930\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.6946 - accuracy: 0.5130\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 0.6645 - accuracy: 1.0000\n",
            "Loss: 0.6645466685295105, Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, RepeatVector\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Create a sample dataset\n",
        "data = np.random.rand(1000, 10, 1)\n",
        "labels = np.random.randint(0, 2, size=1000)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the autoencoder model\n",
        "inputs = Input(shape=(10, 1))\n",
        "\n",
        "# Encoder\n",
        "encoded = LSTM(8, activation='relu')(inputs)\n",
        "\n",
        "# Classifier\n",
        "classification = Dense(16, activation='relu')(encoded)\n",
        "classification = Dropout(0.5)(classification)\n",
        "classification = Dense(1, activation='sigmoid')(classification)\n",
        "\n",
        "# Decoder\n",
        "decoded = RepeatVector(10)(encoded)\n",
        "decoded = LSTM(1, activation='relu', return_sequences=True)(decoded)\n",
        "\n",
        "# Define the autoencoder model\n",
        "autoencoder = Model(inputs, [decoded, classification])\n",
        "\n",
        "# Define the loss weights\n",
        "loss_weights = [1.0, 0.5]\n",
        "\n",
        "# Compile the model\n",
        "autoencoder.compile(optimizer='adam', loss=['mse', 'binary_crossentropy'], loss_weights=loss_weights)\n",
        "\n",
        "# Train the model end-to-end\n",
        "batch_size = 32\n",
        "epochs = 50\n",
        "autoencoder.fit(x_train, [x_train, y_train], batch_size=batch_size, epochs=epochs, validation_split=0.2)\n",
        "\n",
        "# Get the encoded features\n",
        "encoder = Model(inputs, encoded)\n",
        "encoded_features_train = encoder.predict(x_train)\n",
        "encoded_features_test = encoder.predict(x_test)\n",
        "\n",
        "# Train an SVM on the encoded features\n",
        "svm = SVC(kernel='rbf', gamma='scale')\n",
        "svm.fit(encoded_features_train, y_train)\n",
        "\n",
        "# Make predictions using the SVM\n",
        "y_pred = svm.predict(encoded_features_test)\n",
        "\n",
        "# Compute the accuracy and confusion matrix on the predictions of the SVM\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print('Accuracy:', acc)\n",
        "print('Confusion matrix:', cm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWMGnYna9R7f",
        "outputId": "8c1d7107-6fa7-4d1e-81cd-1e4156b2b5a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "20/20 [==============================] - 6s 41ms/step - loss: 0.6227 - lstm_33_loss: 0.2760 - dense_9_loss: 0.6935 - val_loss: 0.5884 - val_lstm_33_loss: 0.2401 - val_dense_9_loss: 0.6966\n",
            "Epoch 2/50\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.5721 - lstm_33_loss: 0.2239 - dense_9_loss: 0.6964 - val_loss: 0.5348 - val_lstm_33_loss: 0.1868 - val_dense_9_loss: 0.6959\n",
            "Epoch 3/50\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.5111 - lstm_33_loss: 0.1625 - dense_9_loss: 0.6972 - val_loss: 0.4689 - val_lstm_33_loss: 0.1212 - val_dense_9_loss: 0.6953\n",
            "Epoch 4/50\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.4465 - lstm_33_loss: 0.0985 - dense_9_loss: 0.6960 - val_loss: 0.4261 - val_lstm_33_loss: 0.0793 - val_dense_9_loss: 0.6935\n",
            "Epoch 5/50\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.4320 - lstm_33_loss: 0.0817 - dense_9_loss: 0.7005 - val_loss: 0.4255 - val_lstm_33_loss: 0.0792 - val_dense_9_loss: 0.6926\n",
            "Epoch 6/50\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.4320 - lstm_33_loss: 0.0811 - dense_9_loss: 0.7017 - val_loss: 0.4251 - val_lstm_33_loss: 0.0790 - val_dense_9_loss: 0.6922\n",
            "Epoch 7/50\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.4273 - lstm_33_loss: 0.0806 - dense_9_loss: 0.6934 - val_loss: 0.4248 - val_lstm_33_loss: 0.0787 - val_dense_9_loss: 0.6922\n",
            "Epoch 8/50\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.4282 - lstm_33_loss: 0.0803 - dense_9_loss: 0.6958 - val_loss: 0.4243 - val_lstm_33_loss: 0.0784 - val_dense_9_loss: 0.6919\n",
            "Epoch 9/50\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 0.4297 - lstm_33_loss: 0.0800 - dense_9_loss: 0.6995 - val_loss: 0.4245 - val_lstm_33_loss: 0.0781 - val_dense_9_loss: 0.6929\n",
            "Epoch 10/50\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 0.4297 - lstm_33_loss: 0.0798 - dense_9_loss: 0.6998 - val_loss: 0.4243 - val_lstm_33_loss: 0.0779 - val_dense_9_loss: 0.6929\n",
            "Epoch 11/50\n",
            "20/20 [==============================] - 0s 19ms/step - loss: 0.4276 - lstm_33_loss: 0.0795 - dense_9_loss: 0.6963 - val_loss: 0.4240 - val_lstm_33_loss: 0.0775 - val_dense_9_loss: 0.6930\n",
            "Epoch 12/50\n",
            "20/20 [==============================] - 0s 18ms/step - loss: 0.4309 - lstm_33_loss: 0.0792 - dense_9_loss: 0.7034 - val_loss: 0.4236 - val_lstm_33_loss: 0.0773 - val_dense_9_loss: 0.6927\n",
            "Epoch 13/50\n",
            "20/20 [==============================] - 0s 18ms/step - loss: 0.4275 - lstm_33_loss: 0.0790 - dense_9_loss: 0.6970 - val_loss: 0.4233 - val_lstm_33_loss: 0.0770 - val_dense_9_loss: 0.6927\n",
            "Epoch 14/50\n",
            "20/20 [==============================] - 0s 17ms/step - loss: 0.4261 - lstm_33_loss: 0.0787 - dense_9_loss: 0.6948 - val_loss: 0.4229 - val_lstm_33_loss: 0.0767 - val_dense_9_loss: 0.6925\n",
            "Epoch 15/50\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.4246 - lstm_33_loss: 0.0783 - dense_9_loss: 0.6925 - val_loss: 0.4224 - val_lstm_33_loss: 0.0763 - val_dense_9_loss: 0.6921\n",
            "Epoch 16/50\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.4285 - lstm_33_loss: 0.0781 - dense_9_loss: 0.7008 - val_loss: 0.4227 - val_lstm_33_loss: 0.0763 - val_dense_9_loss: 0.6928\n",
            "Epoch 17/50\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.4246 - lstm_33_loss: 0.0780 - dense_9_loss: 0.6931 - val_loss: 0.4223 - val_lstm_33_loss: 0.0760 - val_dense_9_loss: 0.6927\n",
            "Epoch 18/50\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.4251 - lstm_33_loss: 0.0777 - dense_9_loss: 0.6948 - val_loss: 0.4220 - val_lstm_33_loss: 0.0757 - val_dense_9_loss: 0.6926\n",
            "Epoch 19/50\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.4241 - lstm_33_loss: 0.0775 - dense_9_loss: 0.6932 - val_loss: 0.4216 - val_lstm_33_loss: 0.0755 - val_dense_9_loss: 0.6923\n",
            "Epoch 20/50\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.4255 - lstm_33_loss: 0.0773 - dense_9_loss: 0.6963 - val_loss: 0.4214 - val_lstm_33_loss: 0.0753 - val_dense_9_loss: 0.6921\n",
            "Epoch 21/50\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.4242 - lstm_33_loss: 0.0771 - dense_9_loss: 0.6941 - val_loss: 0.4214 - val_lstm_33_loss: 0.0752 - val_dense_9_loss: 0.6924\n",
            "Epoch 22/50\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.4254 - lstm_33_loss: 0.0771 - dense_9_loss: 0.6966 - val_loss: 0.4215 - val_lstm_33_loss: 0.0751 - val_dense_9_loss: 0.6928\n",
            "Epoch 23/50\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.4236 - lstm_33_loss: 0.0769 - dense_9_loss: 0.6934 - val_loss: 0.4214 - val_lstm_33_loss: 0.0750 - val_dense_9_loss: 0.6928\n",
            "Epoch 24/50\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.4259 - lstm_33_loss: 0.0768 - dense_9_loss: 0.6982 - val_loss: 0.4208 - val_lstm_33_loss: 0.0748 - val_dense_9_loss: 0.6920\n",
            "Epoch 25/50\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.4246 - lstm_33_loss: 0.0767 - dense_9_loss: 0.6958 - val_loss: 0.4208 - val_lstm_33_loss: 0.0747 - val_dense_9_loss: 0.6922\n",
            "Epoch 26/50\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.4220 - lstm_33_loss: 0.0766 - dense_9_loss: 0.6909 - val_loss: 0.4207 - val_lstm_33_loss: 0.0745 - val_dense_9_loss: 0.6924\n",
            "Epoch 27/50\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.4232 - lstm_33_loss: 0.0764 - dense_9_loss: 0.6935 - val_loss: 0.4207 - val_lstm_33_loss: 0.0745 - val_dense_9_loss: 0.6926\n",
            "Epoch 28/50\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.4236 - lstm_33_loss: 0.0764 - dense_9_loss: 0.6943 - val_loss: 0.4208 - val_lstm_33_loss: 0.0744 - val_dense_9_loss: 0.6927\n",
            "Epoch 29/50\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.4249 - lstm_33_loss: 0.0764 - dense_9_loss: 0.6971 - val_loss: 0.4206 - val_lstm_33_loss: 0.0743 - val_dense_9_loss: 0.6926\n",
            "Epoch 30/50\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.4235 - lstm_33_loss: 0.0763 - dense_9_loss: 0.6945 - val_loss: 0.4203 - val_lstm_33_loss: 0.0743 - val_dense_9_loss: 0.6919\n",
            "Epoch 31/50\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.4235 - lstm_33_loss: 0.0762 - dense_9_loss: 0.6946 - val_loss: 0.4202 - val_lstm_33_loss: 0.0742 - val_dense_9_loss: 0.6920\n",
            "Epoch 32/50\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.4231 - lstm_33_loss: 0.0761 - dense_9_loss: 0.6939 - val_loss: 0.4200 - val_lstm_33_loss: 0.0741 - val_dense_9_loss: 0.6919\n",
            "Epoch 33/50\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.4240 - lstm_33_loss: 0.0761 - dense_9_loss: 0.6957 - val_loss: 0.4202 - val_lstm_33_loss: 0.0741 - val_dense_9_loss: 0.6921\n",
            "Epoch 34/50\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.4223 - lstm_33_loss: 0.0761 - dense_9_loss: 0.6923 - val_loss: 0.4201 - val_lstm_33_loss: 0.0741 - val_dense_9_loss: 0.6920\n",
            "Epoch 35/50\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.4233 - lstm_33_loss: 0.0760 - dense_9_loss: 0.6946 - val_loss: 0.4200 - val_lstm_33_loss: 0.0741 - val_dense_9_loss: 0.6918\n",
            "Epoch 36/50\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.4229 - lstm_33_loss: 0.0760 - dense_9_loss: 0.6939 - val_loss: 0.4201 - val_lstm_33_loss: 0.0740 - val_dense_9_loss: 0.6921\n",
            "Epoch 37/50\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.4226 - lstm_33_loss: 0.0759 - dense_9_loss: 0.6935 - val_loss: 0.4197 - val_lstm_33_loss: 0.0739 - val_dense_9_loss: 0.6915\n",
            "Epoch 38/50\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.4214 - lstm_33_loss: 0.0759 - dense_9_loss: 0.6910 - val_loss: 0.4199 - val_lstm_33_loss: 0.0739 - val_dense_9_loss: 0.6920\n",
            "Epoch 39/50\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.4225 - lstm_33_loss: 0.0759 - dense_9_loss: 0.6933 - val_loss: 0.4200 - val_lstm_33_loss: 0.0739 - val_dense_9_loss: 0.6922\n",
            "Epoch 40/50\n",
            "20/20 [==============================] - 0s 14ms/step - loss: 0.4226 - lstm_33_loss: 0.0758 - dense_9_loss: 0.6936 - val_loss: 0.4199 - val_lstm_33_loss: 0.0738 - val_dense_9_loss: 0.6921\n",
            "Epoch 41/50\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.4228 - lstm_33_loss: 0.0758 - dense_9_loss: 0.6940 - val_loss: 0.4197 - val_lstm_33_loss: 0.0738 - val_dense_9_loss: 0.6919\n",
            "Epoch 42/50\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.4242 - lstm_33_loss: 0.0757 - dense_9_loss: 0.6969 - val_loss: 0.4197 - val_lstm_33_loss: 0.0738 - val_dense_9_loss: 0.6918\n",
            "Epoch 43/50\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.4250 - lstm_33_loss: 0.0758 - dense_9_loss: 0.6985 - val_loss: 0.4201 - val_lstm_33_loss: 0.0739 - val_dense_9_loss: 0.6923\n",
            "Epoch 44/50\n",
            "20/20 [==============================] - 0s 15ms/step - loss: 0.4225 - lstm_33_loss: 0.0758 - dense_9_loss: 0.6934 - val_loss: 0.4201 - val_lstm_33_loss: 0.0738 - val_dense_9_loss: 0.6925\n",
            "Epoch 45/50\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.4220 - lstm_33_loss: 0.0757 - dense_9_loss: 0.6925 - val_loss: 0.4197 - val_lstm_33_loss: 0.0737 - val_dense_9_loss: 0.6919\n",
            "Epoch 46/50\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.4222 - lstm_33_loss: 0.0757 - dense_9_loss: 0.6930 - val_loss: 0.4199 - val_lstm_33_loss: 0.0737 - val_dense_9_loss: 0.6923\n",
            "Epoch 47/50\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.4227 - lstm_33_loss: 0.0756 - dense_9_loss: 0.6943 - val_loss: 0.4195 - val_lstm_33_loss: 0.0737 - val_dense_9_loss: 0.6917\n",
            "Epoch 48/50\n",
            "20/20 [==============================] - 0s 13ms/step - loss: 0.4226 - lstm_33_loss: 0.0756 - dense_9_loss: 0.6941 - val_loss: 0.4195 - val_lstm_33_loss: 0.0737 - val_dense_9_loss: 0.6917\n",
            "Epoch 49/50\n",
            "20/20 [==============================] - 0s 12ms/step - loss: 0.4223 - lstm_33_loss: 0.0756 - dense_9_loss: 0.6935 - val_loss: 0.4198 - val_lstm_33_loss: 0.0737 - val_dense_9_loss: 0.6923\n",
            "Epoch 50/50\n",
            "20/20 [==============================] - 0s 11ms/step - loss: 0.4210 - lstm_33_loss: 0.0755 - dense_9_loss: 0.6910 - val_loss: 0.4199 - val_lstm_33_loss: 0.0736 - val_dense_9_loss: 0.6925\n",
            "25/25 [==============================] - 0s 3ms/step\n",
            "7/7 [==============================] - 0s 3ms/step\n",
            "Accuracy: 0.52\n",
            "Confusion matrix: [[59 42]\n",
            " [54 45]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, RepeatVector\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Create a sample dataset\n",
        "data = np.random.rand(1000, 10, 1)\n",
        "labels = np.random.randint(0, 2, size=1000)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the autoencoder model\n",
        "inputs = Input(shape=(10, 1))\n",
        "\n",
        "# Encoder\n",
        "encoded = LSTM(16, activation='relu', return_sequences=True)(inputs)\n",
        "encoded = LSTM(8, activation='relu', return_sequences=True)(encoded)\n",
        "encoded = LSTM(4, activation='relu')(encoded)\n",
        "\n",
        "# Classifier\n",
        "classification = Dense(16, activation='relu')(encoded)\n",
        "classification = Dropout(0.5)(classification)\n",
        "classification = Dense(1, activation='sigmoid')(classification)\n",
        "\n",
        "# Decoder\n",
        "decoded = RepeatVector(10)(encoded)\n",
        "decoded = LSTM(8, activation='relu', return_sequences=True)(decoded)\n",
        "decoded = LSTM(16, activation='relu', return_sequences=True)(decoded)\n",
        "decoded = LSTM(1, activation='relu')(decoded)\n",
        "\n",
        "# Define the autoencoder model\n",
        "autoencoder = Model(inputs, [decoded, classification])\n",
        "\n",
        "# Define the loss weights\n",
        "loss_weights = [1.0, 0.5]\n",
        "\n",
        "# Compile the model\n",
        "autoencoder.compile(optimizer='adam', loss=['mse', 'binary_crossentropy'], loss_weights=loss_weights)\n",
        "\n",
        "# Train the model end-to-end\n",
        "batch_size = 32\n",
        "epochs = 50\n",
        "autoencoder.fit(x_train, [x_train, y_train], batch_size=batch_size, epochs=epochs, validation_split=0.2)\n",
        "\n",
        "# Get the encoded features\n",
        "encoder = Model(inputs, encoded)\n",
        "encoded_features_train = encoder.predict(x_train)\n",
        "encoded_features_test = encoder.predict(x_test)\n",
        "\n",
        "# Train an SVM on the encoded features\n",
        "svm = SVC(kernel='rbf', gamma='scale')\n",
        "svm.fit(encoded_features_train, y_train)\n",
        "\n",
        "# Make predictions using the SVM\n",
        "y_pred = svm.predict(encoded_features_test)\n",
        "\n",
        "# Compute the accuracy and confusion matrix on the predictions of the SVM\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print('Accuracy:', acc)\n",
        "print('Confusion matrix:', cm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OseN_GN_gTR",
        "outputId": "67b72b94-1eb7-4365-bc52-98784fab4d53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "20/20 [==============================] - 10s 86ms/step - loss: 0.6741 - lstm_39_loss: 0.3274 - dense_11_loss: 0.6932 - val_loss: 0.6614 - val_lstm_39_loss: 0.3148 - val_dense_11_loss: 0.6930\n",
            "Epoch 2/50\n",
            "20/20 [==============================] - 1s 30ms/step - loss: 0.6196 - lstm_39_loss: 0.2728 - dense_11_loss: 0.6937 - val_loss: 0.5794 - val_lstm_39_loss: 0.2328 - val_dense_11_loss: 0.6931\n",
            "Epoch 3/50\n",
            "20/20 [==============================] - 1s 30ms/step - loss: 0.4973 - lstm_39_loss: 0.1509 - dense_11_loss: 0.6929 - val_loss: 0.4331 - val_lstm_39_loss: 0.0865 - val_dense_11_loss: 0.6933\n",
            "Epoch 4/50\n",
            "20/20 [==============================] - 1s 30ms/step - loss: 0.4320 - lstm_39_loss: 0.0849 - dense_11_loss: 0.6942 - val_loss: 0.4299 - val_lstm_39_loss: 0.0834 - val_dense_11_loss: 0.6930\n",
            "Epoch 5/50\n",
            "20/20 [==============================] - 1s 29ms/step - loss: 0.4275 - lstm_39_loss: 0.0804 - dense_11_loss: 0.6942 - val_loss: 0.4275 - val_lstm_39_loss: 0.0811 - val_dense_11_loss: 0.6929\n",
            "Epoch 6/50\n",
            "20/20 [==============================] - 1s 31ms/step - loss: 0.4264 - lstm_39_loss: 0.0795 - dense_11_loss: 0.6938 - val_loss: 0.4268 - val_lstm_39_loss: 0.0804 - val_dense_11_loss: 0.6928\n",
            "Epoch 7/50\n",
            "20/20 [==============================] - 1s 30ms/step - loss: 0.4252 - lstm_39_loss: 0.0790 - dense_11_loss: 0.6924 - val_loss: 0.4262 - val_lstm_39_loss: 0.0798 - val_dense_11_loss: 0.6928\n",
            "Epoch 8/50\n",
            "20/20 [==============================] - 1s 29ms/step - loss: 0.4258 - lstm_39_loss: 0.0783 - dense_11_loss: 0.6950 - val_loss: 0.4257 - val_lstm_39_loss: 0.0793 - val_dense_11_loss: 0.6928\n",
            "Epoch 9/50\n",
            "20/20 [==============================] - 1s 30ms/step - loss: 0.4242 - lstm_39_loss: 0.0778 - dense_11_loss: 0.6929 - val_loss: 0.4254 - val_lstm_39_loss: 0.0790 - val_dense_11_loss: 0.6928\n",
            "Epoch 10/50\n",
            "20/20 [==============================] - 1s 28ms/step - loss: 0.4249 - lstm_39_loss: 0.0775 - dense_11_loss: 0.6949 - val_loss: 0.4253 - val_lstm_39_loss: 0.0789 - val_dense_11_loss: 0.6928\n",
            "Epoch 11/50\n",
            "20/20 [==============================] - 1s 30ms/step - loss: 0.4234 - lstm_39_loss: 0.0773 - dense_11_loss: 0.6921 - val_loss: 0.4252 - val_lstm_39_loss: 0.0788 - val_dense_11_loss: 0.6928\n",
            "Epoch 12/50\n",
            "20/20 [==============================] - 1s 28ms/step - loss: 0.4233 - lstm_39_loss: 0.0773 - dense_11_loss: 0.6922 - val_loss: 0.4251 - val_lstm_39_loss: 0.0787 - val_dense_11_loss: 0.6928\n",
            "Epoch 13/50\n",
            "20/20 [==============================] - 1s 28ms/step - loss: 0.4236 - lstm_39_loss: 0.0773 - dense_11_loss: 0.6926 - val_loss: 0.4249 - val_lstm_39_loss: 0.0786 - val_dense_11_loss: 0.6928\n",
            "Epoch 14/50\n",
            "20/20 [==============================] - 1s 32ms/step - loss: 0.4240 - lstm_39_loss: 0.0771 - dense_11_loss: 0.6937 - val_loss: 0.4249 - val_lstm_39_loss: 0.0785 - val_dense_11_loss: 0.6928\n",
            "Epoch 15/50\n",
            "20/20 [==============================] - 1s 39ms/step - loss: 0.4237 - lstm_39_loss: 0.0771 - dense_11_loss: 0.6933 - val_loss: 0.4247 - val_lstm_39_loss: 0.0784 - val_dense_11_loss: 0.6928\n",
            "Epoch 16/50\n",
            "20/20 [==============================] - 1s 41ms/step - loss: 0.4238 - lstm_39_loss: 0.0770 - dense_11_loss: 0.6937 - val_loss: 0.4246 - val_lstm_39_loss: 0.0783 - val_dense_11_loss: 0.6928\n",
            "Epoch 17/50\n",
            "20/20 [==============================] - 1s 42ms/step - loss: 0.4228 - lstm_39_loss: 0.0770 - dense_11_loss: 0.6916 - val_loss: 0.4246 - val_lstm_39_loss: 0.0782 - val_dense_11_loss: 0.6928\n",
            "Epoch 18/50\n",
            "20/20 [==============================] - 1s 32ms/step - loss: 0.4223 - lstm_39_loss: 0.0769 - dense_11_loss: 0.6909 - val_loss: 0.4245 - val_lstm_39_loss: 0.0781 - val_dense_11_loss: 0.6928\n",
            "Epoch 19/50\n",
            "20/20 [==============================] - 1s 29ms/step - loss: 0.4240 - lstm_39_loss: 0.0767 - dense_11_loss: 0.6947 - val_loss: 0.4243 - val_lstm_39_loss: 0.0780 - val_dense_11_loss: 0.6928\n",
            "Epoch 20/50\n",
            "20/20 [==============================] - 1s 29ms/step - loss: 0.4231 - lstm_39_loss: 0.0766 - dense_11_loss: 0.6931 - val_loss: 0.4242 - val_lstm_39_loss: 0.0778 - val_dense_11_loss: 0.6928\n",
            "Epoch 21/50\n",
            "20/20 [==============================] - 1s 30ms/step - loss: 0.4230 - lstm_39_loss: 0.0765 - dense_11_loss: 0.6931 - val_loss: 0.4242 - val_lstm_39_loss: 0.0778 - val_dense_11_loss: 0.6928\n",
            "Epoch 22/50\n",
            "20/20 [==============================] - 1s 29ms/step - loss: 0.4234 - lstm_39_loss: 0.0764 - dense_11_loss: 0.6940 - val_loss: 0.4242 - val_lstm_39_loss: 0.0778 - val_dense_11_loss: 0.6928\n",
            "Epoch 23/50\n",
            "20/20 [==============================] - 1s 28ms/step - loss: 0.4230 - lstm_39_loss: 0.0764 - dense_11_loss: 0.6934 - val_loss: 0.4241 - val_lstm_39_loss: 0.0777 - val_dense_11_loss: 0.6928\n",
            "Epoch 24/50\n",
            "20/20 [==============================] - 1s 30ms/step - loss: 0.4228 - lstm_39_loss: 0.0763 - dense_11_loss: 0.6931 - val_loss: 0.4239 - val_lstm_39_loss: 0.0775 - val_dense_11_loss: 0.6928\n",
            "Epoch 25/50\n",
            "20/20 [==============================] - 1s 31ms/step - loss: 0.4223 - lstm_39_loss: 0.0762 - dense_11_loss: 0.6922 - val_loss: 0.4239 - val_lstm_39_loss: 0.0775 - val_dense_11_loss: 0.6928\n",
            "Epoch 26/50\n",
            "20/20 [==============================] - 1s 28ms/step - loss: 0.4225 - lstm_39_loss: 0.0761 - dense_11_loss: 0.6928 - val_loss: 0.4238 - val_lstm_39_loss: 0.0774 - val_dense_11_loss: 0.6928\n",
            "Epoch 27/50\n",
            "20/20 [==============================] - 1s 28ms/step - loss: 0.4229 - lstm_39_loss: 0.0760 - dense_11_loss: 0.6937 - val_loss: 0.4237 - val_lstm_39_loss: 0.0774 - val_dense_11_loss: 0.6927\n",
            "Epoch 28/50\n",
            "20/20 [==============================] - 1s 30ms/step - loss: 0.4234 - lstm_39_loss: 0.0761 - dense_11_loss: 0.6947 - val_loss: 0.4238 - val_lstm_39_loss: 0.0774 - val_dense_11_loss: 0.6928\n",
            "Epoch 29/50\n",
            "20/20 [==============================] - 1s 29ms/step - loss: 0.4225 - lstm_39_loss: 0.0760 - dense_11_loss: 0.6929 - val_loss: 0.4239 - val_lstm_39_loss: 0.0774 - val_dense_11_loss: 0.6930\n",
            "Epoch 30/50\n",
            "20/20 [==============================] - 1s 29ms/step - loss: 0.4224 - lstm_39_loss: 0.0760 - dense_11_loss: 0.6928 - val_loss: 0.4239 - val_lstm_39_loss: 0.0773 - val_dense_11_loss: 0.6930\n",
            "Epoch 31/50\n",
            "20/20 [==============================] - 1s 28ms/step - loss: 0.4226 - lstm_39_loss: 0.0760 - dense_11_loss: 0.6931 - val_loss: 0.4239 - val_lstm_39_loss: 0.0774 - val_dense_11_loss: 0.6931\n",
            "Epoch 32/50\n",
            "20/20 [==============================] - 1s 30ms/step - loss: 0.4223 - lstm_39_loss: 0.0760 - dense_11_loss: 0.6925 - val_loss: 0.4239 - val_lstm_39_loss: 0.0774 - val_dense_11_loss: 0.6930\n",
            "Epoch 33/50\n",
            "20/20 [==============================] - 1s 31ms/step - loss: 0.4225 - lstm_39_loss: 0.0760 - dense_11_loss: 0.6931 - val_loss: 0.4238 - val_lstm_39_loss: 0.0773 - val_dense_11_loss: 0.6930\n",
            "Epoch 34/50\n",
            "20/20 [==============================] - 1s 30ms/step - loss: 0.4223 - lstm_39_loss: 0.0760 - dense_11_loss: 0.6927 - val_loss: 0.4239 - val_lstm_39_loss: 0.0773 - val_dense_11_loss: 0.6930\n",
            "Epoch 35/50\n",
            "20/20 [==============================] - 1s 41ms/step - loss: 0.4223 - lstm_39_loss: 0.0760 - dense_11_loss: 0.6927 - val_loss: 0.4238 - val_lstm_39_loss: 0.0773 - val_dense_11_loss: 0.6930\n",
            "Epoch 36/50\n",
            "20/20 [==============================] - 1s 40ms/step - loss: 0.4224 - lstm_39_loss: 0.0759 - dense_11_loss: 0.6929 - val_loss: 0.4238 - val_lstm_39_loss: 0.0773 - val_dense_11_loss: 0.6930\n",
            "Epoch 37/50\n",
            "20/20 [==============================] - 1s 42ms/step - loss: 0.4223 - lstm_39_loss: 0.0760 - dense_11_loss: 0.6927 - val_loss: 0.4239 - val_lstm_39_loss: 0.0774 - val_dense_11_loss: 0.6930\n",
            "Epoch 38/50\n",
            "20/20 [==============================] - 1s 34ms/step - loss: 0.4222 - lstm_39_loss: 0.0759 - dense_11_loss: 0.6925 - val_loss: 0.4239 - val_lstm_39_loss: 0.0774 - val_dense_11_loss: 0.6930\n",
            "Epoch 39/50\n",
            "20/20 [==============================] - 1s 30ms/step - loss: 0.4224 - lstm_39_loss: 0.0759 - dense_11_loss: 0.6928 - val_loss: 0.4238 - val_lstm_39_loss: 0.0773 - val_dense_11_loss: 0.6931\n",
            "Epoch 40/50\n",
            "20/20 [==============================] - 1s 29ms/step - loss: 0.4221 - lstm_39_loss: 0.0760 - dense_11_loss: 0.6922 - val_loss: 0.4239 - val_lstm_39_loss: 0.0773 - val_dense_11_loss: 0.6930\n",
            "Epoch 41/50\n",
            "20/20 [==============================] - 1s 30ms/step - loss: 0.4225 - lstm_39_loss: 0.0760 - dense_11_loss: 0.6930 - val_loss: 0.4238 - val_lstm_39_loss: 0.0773 - val_dense_11_loss: 0.6930\n",
            "Epoch 42/50\n",
            "20/20 [==============================] - 1s 29ms/step - loss: 0.4220 - lstm_39_loss: 0.0759 - dense_11_loss: 0.6921 - val_loss: 0.4239 - val_lstm_39_loss: 0.0773 - val_dense_11_loss: 0.6931\n",
            "Epoch 43/50\n",
            "20/20 [==============================] - 1s 30ms/step - loss: 0.4219 - lstm_39_loss: 0.0759 - dense_11_loss: 0.6918 - val_loss: 0.4238 - val_lstm_39_loss: 0.0774 - val_dense_11_loss: 0.6930\n",
            "Epoch 44/50\n",
            "20/20 [==============================] - 1s 29ms/step - loss: 0.4221 - lstm_39_loss: 0.0759 - dense_11_loss: 0.6923 - val_loss: 0.4239 - val_lstm_39_loss: 0.0773 - val_dense_11_loss: 0.6931\n",
            "Epoch 45/50\n",
            "20/20 [==============================] - 1s 30ms/step - loss: 0.4222 - lstm_39_loss: 0.0759 - dense_11_loss: 0.6926 - val_loss: 0.4238 - val_lstm_39_loss: 0.0773 - val_dense_11_loss: 0.6931\n",
            "Epoch 46/50\n",
            "20/20 [==============================] - 1s 30ms/step - loss: 0.4227 - lstm_39_loss: 0.0759 - dense_11_loss: 0.6935 - val_loss: 0.4238 - val_lstm_39_loss: 0.0773 - val_dense_11_loss: 0.6930\n",
            "Epoch 47/50\n",
            "20/20 [==============================] - 1s 28ms/step - loss: 0.4224 - lstm_39_loss: 0.0759 - dense_11_loss: 0.6929 - val_loss: 0.4238 - val_lstm_39_loss: 0.0773 - val_dense_11_loss: 0.6930\n",
            "Epoch 48/50\n",
            "20/20 [==============================] - 1s 28ms/step - loss: 0.4224 - lstm_39_loss: 0.0759 - dense_11_loss: 0.6929 - val_loss: 0.4238 - val_lstm_39_loss: 0.0773 - val_dense_11_loss: 0.6930\n",
            "Epoch 49/50\n",
            "20/20 [==============================] - 1s 31ms/step - loss: 0.4223 - lstm_39_loss: 0.0759 - dense_11_loss: 0.6927 - val_loss: 0.4238 - val_lstm_39_loss: 0.0773 - val_dense_11_loss: 0.6930\n",
            "Epoch 50/50\n",
            "20/20 [==============================] - 1s 29ms/step - loss: 0.4221 - lstm_39_loss: 0.0759 - dense_11_loss: 0.6924 - val_loss: 0.4238 - val_lstm_39_loss: 0.0773 - val_dense_11_loss: 0.6930\n",
            "25/25 [==============================] - 1s 5ms/step\n",
            "7/7 [==============================] - 1s 6ms/step\n",
            "Accuracy: 0.48\n",
            "Confusion matrix: [[ 96   4]\n",
            " [100   0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Generate sample data\n",
        "num_samples = 1000\n",
        "seq_len = 10\n",
        "num_features = 5\n",
        "num_classes = 2\n",
        "\n",
        "X = np.random.randn(num_samples, seq_len, num_features)\n",
        "y = np.random.randint(num_classes, size=num_samples)\n"
      ],
      "metadata": {
        "id": "_WAylUmeGwPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Dense, Concatenate, Flatten, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Input, LSTM, RepeatVector, TimeDistributed\n",
        "\n",
        "# Define input shape\n",
        "inputs = Input(shape=(seq_len, num_features))\n",
        "\n",
        "# Encoder\n",
        "encoded = LSTM(64, return_sequences=True)(inputs)\n",
        "encoded = LSTM(32, return_sequences=True)(encoded)\n",
        "encoded = LSTM(16)(encoded)\n",
        "\n",
        "# Decoder\n",
        "decoded = RepeatVector(seq_len)(encoded)\n",
        "decoded = LSTM(32, return_sequences=True)(decoded)\n",
        "decoded = LSTM(64, return_sequences=True)(decoded)\n",
        "decoded = TimeDistributed(Dense(num_features))(decoded)\n",
        "\n",
        "# Classifier\n",
        "classifier = Flatten()(encoded)\n",
        "classifier = Dense(32, activation='relu')(classifier)\n",
        "classifier = Dropout(0.5)(classifier)\n",
        "classifier_output = Dense(num_classes, activation='softmax')(classifier)\n",
        "\n",
        "# Define autoencoder model\n",
        "autoencoder = Model(inputs, decoded)\n",
        "\n",
        "# Define classifier model\n",
        "classifier_model = Model(inputs, classifier_output)\n",
        "\n",
        "# Define combined model\n",
        "combined_model = Model(inputs, [decoded, classifier_output])\n",
        "\n",
        "# Define optimizer and loss functions\n",
        "optimizer = Adam(lr=0.001)\n",
        "autoencoder.compile(optimizer=optimizer, loss=['mse', 'categorical_crossentropy'], loss_weights=[0.5, 0.5])\n",
        "classifier_model.compile(optimizer=optimizer, loss='categorical_crossentropy')\n",
        "combined_model.compile(optimizer=optimizer, loss=['mse', 'categorical_crossentropy'], loss_weights=[0.5, 0.5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoPBAPxxGyEJ",
        "outputId": "abacb189-7ff0-4a28-aad6-713eb8232255"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into train and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train_one_hot = to_categorical(y_train)\n",
        "y_test_one_hot = to_categorical(y_test)\n",
        "\n",
        "# Train the model\n",
        "autoencoder.fit(X_train, [X_train, y_train_one_hot], batch_size=32, epochs=50)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss = autoencoder.evaluate(X_test, [X_test, y_test_one_hot])\n",
        "print('Test loss: {:.3f}'.format(test_loss))\n",
        "\n",
        "# Get encoded features for SVM\n",
        "encoded_features_train = autoencoder.predict(X_train)\n",
        "encoded_features_test = autoencoder.predict(X_test)\n",
        "\n",
        "# Train SVM on encoded features\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "svm_model = SVC(kernel='linear')\n",
        "encoded_features_train = encoded_features_train.reshape(encoded_features_train.shape[0], -1)\n",
        "\n",
        "svm_model.fit(encoded_features_train, y_train)\n",
        "\n",
        "# Evaluate SVM on encoded features\n",
        "encoded_features_test = encoded_features_test.reshape(encoded_features_test.shape[0], -1)\n",
        "svm_preds = svm_model.predict(encoded_features_test)\n",
        "svm_acc = np.mean(svm_preds == y_test)\n",
        "print('SVM Accuracy: {:.3f}'.format(svm_acc))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJvSFA6eHCnA",
        "outputId": "1f3448e7-6e4b-4eca-f90c-48ecf019aebe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 0.2139\n",
            "Epoch 2/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.2130\n",
            "Epoch 3/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.2123\n",
            "Epoch 4/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 0.2118\n",
            "Epoch 5/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.2120\n",
            "Epoch 6/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.2132\n",
            "Epoch 7/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 0.2118\n",
            "Epoch 8/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.2114\n",
            "Epoch 9/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 0.2107\n",
            "Epoch 10/50\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 0.2103\n",
            "Epoch 11/50\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 0.2108\n",
            "Epoch 12/50\n",
            "25/25 [==============================] - 1s 38ms/step - loss: 0.2114\n",
            "Epoch 13/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.2111\n",
            "Epoch 14/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.2100\n",
            "Epoch 15/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.2105\n",
            "Epoch 16/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 0.2105\n",
            "Epoch 17/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.2103\n",
            "Epoch 18/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.2092\n",
            "Epoch 19/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 0.2094\n",
            "Epoch 20/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.2099\n",
            "Epoch 21/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.2093\n",
            "Epoch 22/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 0.2084\n",
            "Epoch 23/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.2086\n",
            "Epoch 24/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.2076\n",
            "Epoch 25/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.2095\n",
            "Epoch 26/50\n",
            "25/25 [==============================] - 1s 31ms/step - loss: 0.2082\n",
            "Epoch 27/50\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 0.2061\n",
            "Epoch 28/50\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 0.2044\n",
            "Epoch 29/50\n",
            "25/25 [==============================] - 1s 36ms/step - loss: 0.2051\n",
            "Epoch 30/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 0.2077\n",
            "Epoch 31/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.2072\n",
            "Epoch 32/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.2056\n",
            "Epoch 33/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 0.2044\n",
            "Epoch 34/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 0.2043\n",
            "Epoch 35/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 0.2041\n",
            "Epoch 36/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.2048\n",
            "Epoch 37/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.2056\n",
            "Epoch 38/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.2038\n",
            "Epoch 39/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.2023\n",
            "Epoch 40/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.2017\n",
            "Epoch 41/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.2016\n",
            "Epoch 42/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.2019\n",
            "Epoch 43/50\n",
            "25/25 [==============================] - 1s 30ms/step - loss: 0.2035\n",
            "Epoch 44/50\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 0.2053\n",
            "Epoch 45/50\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 0.2035\n",
            "Epoch 46/50\n",
            "25/25 [==============================] - 1s 37ms/step - loss: 0.2011\n",
            "Epoch 47/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.2016\n",
            "Epoch 48/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 0.2039\n",
            "Epoch 49/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 0.2018\n",
            "Epoch 50/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 0.2006\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5217\n",
            "Test loss: 0.522\n",
            "25/25 [==============================] - 0s 11ms/step\n",
            "7/7 [==============================] - 0s 11ms/step\n",
            "SVM Accuracy: 0.490\n"
          ]
        }
      ]
    }
  ]
}